---
title: "Project 2"
author: "Ciara Whipp"
date: "6/29/2020"
output:
  rmarkdown::github_document:
    toc: true
    toc_depth: 1
params:
  day: "Monday"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
```

## Introduction  

The **OnlineNewsPopularity** data set has a total of 61 variables. There are 2 non-predictive variables, 58 predictive variables, and 1 target variable. The purpose  of this program is to explore how well two different types of models, a liner regression model and an ensemble model, predict the `shares` (target) variable. To do so, we will separate the **OnlineNewsPopularity** data set into training and testing data sets and use the training data set to train the models. Then, we will test the models using the testing data set and compare the accuracy of the two models. We will automate the Rmarkdown file to repeat this process and create a report for each day of the week.  

## Data  

I will use the variables `global_subjectivity`,`global_sentiment_polarity`, `title_subjectivity`, and `title_sentiment_polarity` to create the two predictive models. `global_subjectivity`measures text subjectivity and `title_subjectivity` measures title subjectivity. Both variables take on values between 0 and 1 . The variable `global_sentiment_polarity` measures text sentiment polarity and takes on values between -0.39375 and 0.727840909. `title_sentiment_polarity` measures title polarity and takes on values between -1 and 1. For the polarity variables, where positive values represent positive sentiments, negative values represent negative sentiments, and 0 is neutral.  

Read in **OnlineNewsPopularity.csv**. The data set was download from [this website](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity). Create a new variable called `day` to indicate the day of the week the article was publsiehd. Keep the `shares` variable, the four predictor variables mentioned above, and the new `day` variable. Change `shares` into a binary classification by splitting it into two groups - <1400 will be represented as 0 and ≥1400 will be represented as 1.  

```{r, echo=TRUE, eval=TRUE, message=FALSE}
newsData <- read_csv("OnlineNewsPopularity.csv") %>% 
    mutate(day=ifelse(weekday_is_monday==1, "Monday",
                ifelse(weekday_is_tuesday==1,"Tuesday",
                    ifelse(weekday_is_wednesday==1,"Wednesday",
                        ifelse(weekday_is_thursday==1,"Thursday",
                            ifelse(weekday_is_friday==1,"Friday",
                                ifelse(weekday_is_saturday==1,"Saturday",
                                    "Sunday"))))))) %>%
  select(shares, global_subjectivity, global_sentiment_polarity,
         title_subjectivity, title_sentiment_polarity, day)
newsData$shares <- ifelse(newsData$shares<1400, "0", "1")
newsData$shares <- as.factor(newsData$shares)
```

Split the **newsData** data set into training and testing data sets.  

```{r split, echo=TRUE, eval=TRUE}
set.seed(1)
train <- sample(1:nrow(newsData), size=nrow(newsData)*0.7)
test <- dplyr::setdiff(1:nrow(newsData), train)

newsDataTrain <- newsData[train, ]
newsDataTest <- newsData[test, ]
```

## Summarization  

### Summary Statistics

The summary statistics tables for the training data give the minimum, 1st quantile, median, mean, 3rd quantile, and maximum for `global_subjectivity`,`global_sentiment_polarity`, `title_subjectivity`, and `title_sentiment_polarity` for <1400 shares and ≥1400 shares respectively.  

```{r statTable, echo=TRUE, eval=TRUE}
newsDataLt <- newsDataTrain %>%
  filter(shares=="0") %>%
  select(global_subjectivity, global_sentiment_polarity,
         title_subjectivity, title_sentiment_polarity)
knitr::kable(apply(newsDataLt,2,summary), digits=2,
             caption="Summary Statisitics for <1400 Shares in Training Data")
newsDataGt <- newsDataTrain %>%
  filter(shares=="1") %>%
  select(global_subjectivity, global_sentiment_polarity,
         title_subjectivity, title_sentiment_polarity)
knitr::kable(apply(newsDataGt,2,summary), digits=2,
             caption="Summary Statisitics for ≥1400 Shares in Training Data")
```

## Plots  

Use `ggpairs` to create graphs that show relationships between numeric variables and summary graphs for character variables and numerical variables by categories of the character variables.  

```{r plot,newsDataGtecho=TRUE, eval=TRUE, message=FALSE}
GGally::ggpairs(newsDataTrain)
```

## Modeling  

### Ensemble Model - Classification Tree

This classification tree aims to predict the `shares` category based on `global_subjectivity`,`global_sentiment_polarity`, `title_subjectivity`, and `title_sentiment_polarity`. Classification trees require the tuning parameter **cp**. `trainControl` is used to determine the "best" **cp** value for this model (cp=0.001 is used). The `preProcess` agrument standardizes the variables.   

```{r rfFit, echo=TRUE, eval=TRUE, results=FALSE}
trCtrl <- trainControl(method="repeatedcv", number=10, repeats=3)
classTreeFit <- train(shares~ global_subjectivity*global_sentiment_polarity*
                 title_sentiment_polarity*title_subjectivity, 
               data=newsDataTrain, 
               method="rpart",
               trControl=trCtrl,
               preProcess=c("center", "scale"),
               tuneGrid=expand.grid(cp=c(0.001,0.0025,0.005,0.0075,
                                         0.01,0.0125,0.015,0.0175,
                                         0.02,0.0225,0.025,0.0275,
                                         0.03,0.0325,0.035,0.0375,
                                         0.04,0.0425,0.045,0.0475,
                                         0.05,0.0525,0.055,0.0575)))
classTreeFit
```

Use the `predict` function to predict the `shares` variable in the **newsDataTest** data set. `confusionMatrix` compares the predicted values to the actual values in the data set and provides the accuracy of the model.  

```{r rfPred, echo=TRUE, eval=TRUE}
classTreePred <- predict(classTreeFit, newdata=newsDataTest)
confusionMatrix(classTreePred, newsDataTest$shares)
```

From the output, we can see this model has an accuracy of 56.48% and therefore, has a misclassification rate of 43.52%.  

### Linear Regression Model - Logistic Regression  

Since our target variable is binary, we can use the binomial distribution to fit a logistic regression model. I choose to model `shares` by the all combinations of main effects and interactions of `global_subjectivity` and `global_sentiment_polarity`, all combinations of main effects and interactions of `global_sentiment_polarity` and `title_sentiment_polarity`, and the main effect of `title_subjectivity`.  

```{r glmFit, echo=TRUE, eval=TRUE}
glmFit <- glm(shares ~ global_subjectivity*global_sentiment_polarity + 
                global_sentiment_polarity*title_sentiment_polarity +
                title_subjectivity,
              data=newsDataTrain,
              family="binomial")
summary(glmFit)
```

Use `prediect` to predict probability of having <1400 shares. Map probabilities less than 0.5 to <1400 shares or 0, and probabilities of greeater than or equal to 0.5 to ≥1400 shares or 1. Use `confusionMatrix` to determine the accuracy of the model.  

```{r glmPred, echo=TRUE, eval=TRUE}
glmPred <- predict(glmFit, newdata=newsDataTest, type="response")
glmPred <- ifelse(glmPred<0.5, "0", "1")
glmPred <- as.factor(glmPred)
confusionMatrix(glmPred, newsDataTest$shares)
```

From the output, we can see this model has an accuracy of 55.03% and therefore, has a misclassification rate of 44.97%.  

## Automation  

The following code chunk is to automate the html reports for each day of the week. Create a variable, **days**, that contains all the unique values of **day** variable in the **newsData** data set and create an hmtl file name (the output files) for each day. Use `lapply` function to apply each day to `params` in the header.

```{r automate, echo=TRUE, eval=FALSE}
days <- unique(newsData$day)
outputFile <- paste0(days, ".html")
params = lapply(days, FUN=function(x){list(day=x)})
reports <- tibble(outputFile, params)
```